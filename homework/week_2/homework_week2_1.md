# 第二周作业1
## 1. 单项选择题
### 1.1 表示学习”主要是指什么？ B (表示学习的主要目标是找到一种方式来转换原始数据，使得转换后的表示能更好地支持后续的任务。例如，在图像识别任务中，原始像素值可能不是一个好的数据表示，而通过某种方法学习到的特征（例如边缘、颜色、形状等）可能会提供更好的性能)
```
A. 学习数据的原始表示
B. 学习数据的有用表示
C. 学习数据的随机表示
D. 学习数据的复杂表示
```
### 1.2 在 NLP 中，最常用的数据表示方法是什么？ C (自然语言处理（NLP）中的数据通常是文本。一种有效的处理文本数据的方法是将其转化为数值或者向量形式，这种转化过程就是数据表示。例如，一个最简单的方法是one-hot编码，每个词被编码为一个很长的向量，这个向量的维度是词汇表的大小，向量的所有元素都是0，除了表示该词的索引位置的元素是1)
```
A. 图像
B. 视频
C. 文本
D. 音频
```
### 1.3 Word2Vec 是一个什么样的模型？ C (Word2Vec是一种用于学习词向量的模型，它通过训练神经网络模型，将语料库中的每个词映射到一个向量，以便使语义上相似的词在向量空间中靠近)
```
A. 用于语音识别的模型
B. 用于图像识别的模型
C. 用于词表示学习的模型
D. 用于视频处理的模型
```
### 1.4 GloVe 模型的主要目标是什么？ C (GloVe模型的目标是学习词向量，这些向量可以捕捉到词的共现信息，即在给定的文本中，哪些词经常在一起出现。例如，在"GloVe模型"这个短语中，"GloVe"和"模型"就是共现的词)
```
A. 在给定的文本中找到最频繁出现的词
B. 在给定的文本中找到最少出现的词
C. 在给定的文本中找到相关性最强的词
D. 在给定的文本中找到最不相关的词
```
### 1.5 表示学习在自然语言处理中的主要应用是什么？ B (表示学习的一个重要应用是语义理解。通过学习到的表示，我们可以更好地理解和解析文本数据。例如，通过学习词的向量表示，我们可以量化词的相似性，并使用这种相似性来理解和生成文本)
```
A. 语音识别
B. 语义理解
C. 图像识别
D. 视频处理
```
### 1.6 Word2Vec 和 GloVe 有什么共同点？ B (Word2Vec和GloVe都是用于学习词向量的模型，它们都能将文本转换为实数向量，以便于机器进行处理。这两种模型的目标都是把词语映射到一个多维空间，使得语义上相似的词在这个空间中靠近)
```
A. 都是图像识别模型
B. 都是词表示学习模型
C. 都是语音识别模型
D. 都是视频处理模型
```
### 1.7 在 OpenAI Embeddings 中，一般采用什么方法对词进行表示？ C (在OpenAI Embeddings中，每个词被表示为一个实数向量。这种表示可以捕获词语的语义，使得语义上相似的词在向量空间中靠近。例如，"猫"和"狗"这两个词，在向量空间中应该比"猫"和"汽车"更靠近)
```
A. 用一个唯一的 ID 表示
B. 用一个独热向量表示
C. 用一个实数向量表示
D. 用一个复数向量表示
```
### 1.8 在词向量中，词的相似度通常用什么衡量？ B (在词向量中，词的相似度通常通过计算它们向量之间的余弦相似度来衡量。余弦相似度可以捕捉到向量的夹角，如果两个向量的方向相似（即夹角小），那么它们的余弦相似度就会高，表示这两个词在语义上是相似的)
```
A. 欧氏距离
B. 余弦相似度
C. 曼哈顿距离
D. 切比雪夫距离
```
### 1.9 在表示学习中，为什么要用非监督学习？ C (在监督学习中，我们需要大量的标签数据，这些数据往往难以获得。而在非监督学习中，我们可以利用大量的未标记数据。因此，在表示学习中，非监督学习是一种常见的方法)
```
A. 因为监督学习太复杂
B. 因为监督学习无法处理大数据
C. 因为监督学习需要太多的标签数据
D. 因为监督学习效果不好
```
### 1.10 在表示学习中，主要使用哪种方法来优化词向量？ B (在表示学习中，我们通常使用随机梯度下降（SGD）方法来优化词向量。SGD是一种迭代方法，每次只用一个（或者一小批）样本来更新参数，这样可以显著降低计算量，加快优化的速度)
```
A. 用反向传播优化
B. 用随机梯度下降优化
C. 用动量法优化
D. 用牛顿法优化
```